{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://mxnet.apache.org/versions/1.5.0/tutorials/gluon/multi_gpu.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:23:03] ../src/base.cc:79: cuDNN lib mismatch: linked-against version 8201 != compiled-against version 8101.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "n_gpu = mx.context.num_gpus()\n",
    "context = [mx.gpu(0), mx.gpu(1)] if n_gpu >= 2 else \\\n",
    "          [mx.gpu(), mx.gpu()] if n_gpu == 1 else \\\n",
    "          [mx.cpu(), mx.cpu()]\n",
    "\n",
    "a = mx.nd.array([1, 2, 3], ctx=context[0])\n",
    "b = mx.nd.array([5, 6, 7], ctx=context[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the network on multiple GPUsÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import init\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Conv2D(channels=6, kernel_size=5, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        nn.Conv2D(channels=16, kernel_size=3, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        nn.Conv2D(channels=16, kernel_size=3, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Dense(120, activation=\"relu\"),\n",
    "        nn.Dense(84, activation=\"relu\"),\n",
    "        nn.Dense(10))\n",
    "\n",
    "net.initialize(init=init.Xavier(), ctx=context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data between GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mx.random.uniform(shape=(100, 10))\n",
    "result = mx.gluon.utils.split_and_load(data, ctx_list=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = mx.gluon.data.vision.MNIST(train=True).transform_first(mx.gluon.data.vision.transforms.ToTensor())\n",
    "val_data = mx.gluon.data.vision.MNIST(train=False).transform_first(mx.gluon.data.vision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_loader = mx.gluon.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = mx.gluon.data.DataLoader(val_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = mx.gluon.Trainer(\n",
    "    params=net.collect_params(),\n",
    "    optimizer='sgd',\n",
    "    optimizer_params={'learning_rate': 0.005},\n",
    ")\n",
    "\n",
    "metric = mx.metric.Accuracy()\n",
    "loss_function = mx.gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:36:33] ../src/kvstore/././comm.h:741: only 0 out of 2 GPU pairs are enabled direct access. It may affect the performance. You can set MXNET_ENABLE_GPU_P2P=0 to turn it off\n",
      "[12:36:33] ../src/kvstore/././comm.h:750: ..\n",
      "[12:36:33] ../src/kvstore/././comm.h:750: ..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 1: accuracy = 0.18065\n",
      "After epoch 2: accuracy = 0.37133333333333335\n",
      "After epoch 3: accuracy = 0.6742833333333333\n",
      "After epoch 4: accuracy = 0.85235\n",
      "After epoch 5: accuracy = 0.8885166666666666\n",
      "After epoch 6: accuracy = 0.9051333333333333\n",
      "After epoch 7: accuracy = 0.9148166666666666\n",
      "After epoch 8: accuracy = 0.9229333333333334\n",
      "After epoch 9: accuracy = 0.9292333333333334\n",
      "After epoch 10: accuracy = 0.9342833333333334\n",
      "After epoch 11: accuracy = 0.9393833333333333\n",
      "After epoch 12: accuracy = 0.9430333333333333\n",
      "After epoch 13: accuracy = 0.9471166666666667\n",
      "After epoch 14: accuracy = 0.9495166666666667\n",
      "After epoch 15: accuracy = 0.9531666666666667\n",
      "After epoch 16: accuracy = 0.9546\n",
      "After epoch 17: accuracy = 0.9572166666666667\n",
      "After epoch 18: accuracy = 0.95825\n",
      "After epoch 19: accuracy = 0.9605166666666667\n",
      "After epoch 20: accuracy = 0.96175\n",
      "After epoch 21: accuracy = 0.9627166666666667\n",
      "After epoch 22: accuracy = 0.9642333333333334\n",
      "After epoch 23: accuracy = 0.9652166666666666\n",
      "After epoch 24: accuracy = 0.9662166666666666\n",
      "After epoch 25: accuracy = 0.9670666666666666\n",
      "After epoch 26: accuracy = 0.9676166666666667\n",
      "After epoch 27: accuracy = 0.96885\n",
      "After epoch 28: accuracy = 0.9698\n",
      "After epoch 29: accuracy = 0.9709166666666667\n",
      "After epoch 30: accuracy = 0.9713\n",
      "After epoch 31: accuracy = 0.9720666666666666\n",
      "After epoch 32: accuracy = 0.9721333333333333\n",
      "After epoch 33: accuracy = 0.97295\n",
      "After epoch 34: accuracy = 0.9736333333333334\n",
      "After epoch 35: accuracy = 0.9739166666666667\n",
      "After epoch 36: accuracy = 0.9753833333333334\n",
      "After epoch 37: accuracy = 0.9747333333333333\n",
      "After epoch 38: accuracy = 0.9756333333333334\n",
      "After epoch 39: accuracy = 0.9761833333333333\n",
      "After epoch 40: accuracy = 0.97645\n",
      "After epoch 41: accuracy = 0.97685\n",
      "After epoch 42: accuracy = 0.9771333333333333\n",
      "After epoch 43: accuracy = 0.9778833333333333\n",
      "After epoch 44: accuracy = 0.9776833333333333\n",
      "After epoch 45: accuracy = 0.9780833333333333\n",
      "After epoch 46: accuracy = 0.9783\n",
      "After epoch 47: accuracy = 0.9792666666666666\n",
      "After epoch 48: accuracy = 0.9792\n",
      "After epoch 49: accuracy = 0.9793333333333333\n",
      "After epoch 50: accuracy = 0.9792\n",
      "After epoch 51: accuracy = 0.9801\n",
      "After epoch 52: accuracy = 0.9805666666666667\n",
      "After epoch 53: accuracy = 0.9807\n",
      "After epoch 54: accuracy = 0.9808\n",
      "After epoch 55: accuracy = 0.9809166666666667\n",
      "After epoch 56: accuracy = 0.9810166666666666\n",
      "After epoch 57: accuracy = 0.9811166666666666\n",
      "After epoch 58: accuracy = 0.9814166666666667\n",
      "After epoch 59: accuracy = 0.9816166666666667\n",
      "After epoch 60: accuracy = 0.9817833333333333\n",
      "After epoch 61: accuracy = 0.9820833333333333\n",
      "After epoch 62: accuracy = 0.9822333333333333\n",
      "After epoch 63: accuracy = 0.9824166666666667\n",
      "After epoch 64: accuracy = 0.9827166666666667\n",
      "After epoch 65: accuracy = 0.9833666666666666\n",
      "After epoch 66: accuracy = 0.98295\n",
      "After epoch 67: accuracy = 0.9835\n",
      "After epoch 68: accuracy = 0.98335\n",
      "After epoch 69: accuracy = 0.9835333333333334\n",
      "After epoch 70: accuracy = 0.9835666666666667\n",
      "After epoch 71: accuracy = 0.9845333333333334\n",
      "After epoch 72: accuracy = 0.98405\n",
      "After epoch 73: accuracy = 0.9842666666666666\n",
      "After epoch 74: accuracy = 0.9846\n",
      "After epoch 75: accuracy = 0.9849333333333333\n",
      "After epoch 76: accuracy = 0.9848\n",
      "After epoch 77: accuracy = 0.9849833333333333\n",
      "After epoch 78: accuracy = 0.9849833333333333\n",
      "After epoch 79: accuracy = 0.9850833333333333\n",
      "After epoch 80: accuracy = 0.9849333333333333\n",
      "After epoch 81: accuracy = 0.98535\n",
      "After epoch 82: accuracy = 0.9858833333333333\n",
      "After epoch 83: accuracy = 0.9858\n",
      "After epoch 84: accuracy = 0.9859166666666667\n",
      "After epoch 85: accuracy = 0.9861333333333333\n",
      "After epoch 86: accuracy = 0.98635\n",
      "After epoch 87: accuracy = 0.9861333333333333\n",
      "After epoch 88: accuracy = 0.9866333333333334\n",
      "After epoch 89: accuracy = 0.9866833333333334\n",
      "After epoch 90: accuracy = 0.9864166666666667\n",
      "After epoch 91: accuracy = 0.9867333333333334\n",
      "After epoch 92: accuracy = 0.9868833333333333\n",
      "After epoch 93: accuracy = 0.9870833333333333\n",
      "After epoch 94: accuracy = 0.9872\n",
      "After epoch 95: accuracy = 0.9869833333333333\n",
      "After epoch 96: accuracy = 0.9868833333333333\n",
      "After epoch 97: accuracy = 0.98715\n",
      "After epoch 98: accuracy = 0.9874\n",
      "After epoch 99: accuracy = 0.9872\n",
      "After epoch 100: accuracy = 0.9876166666666667\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        actual_batch_size = inputs.shape[0]\n",
    "        # Split data among GPUs. Since split_and_load is a deterministic function\n",
    "        # inputs and labels are going to be split in the same way between GPUs.\n",
    "        inputs = mx.gluon.utils.split_and_load(inputs, ctx_list=context, even_split=False)\n",
    "        labels = mx.gluon.utils.split_and_load(labels, ctx_list=context, even_split=False)\n",
    "\n",
    "        # The forward pass and the loss computation need to be wrapped\n",
    "        # in a `record()` scope to make sure the computational graph is\n",
    "        # recorded in order to automatically compute the gradients\n",
    "        # during the backward pass.\n",
    "        with mx.autograd.record():\n",
    "            outputs = [net(input_slice) for input_slice in inputs]\n",
    "            losses = [loss_function(o, l) for o, l in zip(outputs, labels)]\n",
    "\n",
    "        # Iterate over losses to compute gradients for each input slice\n",
    "        for loss in losses:\n",
    "            loss.backward()\n",
    "\n",
    "        # update metric for each output\n",
    "        for l, o in zip(labels, outputs):\n",
    "            metric.update(l, o)\n",
    "\n",
    "        # Update the parameters by stepping the trainer; the batch size\n",
    "        # is required to normalize the gradients by `1 / batch_size`.\n",
    "        trainer.step(batch_size=actual_batch_size, ignore_stale_grad=True)\n",
    "\n",
    "    # Print the evaluation metric and reset it for the next epoch\n",
    "    name, acc = metric.get()\n",
    "    print('After epoch {}: {} = {}'.format(epoch + 1, name, acc))\n",
    "    metric.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('sktime-gluon-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c690c4aacf52c5b35e8c405d3ffa01c0fb45d098d01a1254237bffad00a0de1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
