{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "from gluonts.mx.distribution.piecewise_linear import PiecewiseLinearOutput\n",
    "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.model.seq2seq import MQCNNEstimator\n",
    "from gluonts.mx.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    \"m4_hourly\",\n",
    "    \"m4_daily\",\n",
    "    \"m4_weekly\",\n",
    "    \"m4_monthly\",\n",
    "    \"m4_quarterly\",\n",
    "    \"m4_yearly\",\n",
    "]\n",
    "\n",
    "epochs = 10\n",
    "num_batches_per_epoch = 50\n",
    "estimators = [\n",
    "    MQCNNEstimator,\n",
    "    DeepAREstimator,\n",
    "    partial(\n",
    "        DeepAREstimator,\n",
    "        distr_output=PiecewiseLinearOutput(8),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dataset is TrainDatasets(metadata=MetaData(freq='Q', target=None, feat_static_cat=[CategoricalFeatureInfo(name='feat_static_cat', cardinality='24000')], feat_static_real=[], feat_dynamic_real=[], feat_dynamic_cat=[], prediction_length=8), train=<gluonts.dataset.common.FileDataset object at 0x7fead0fbfa60>, test=<gluonts.dataset.common.FileDataset object at 0x7fead0fbfa30>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "estimator = DeepAREstimator(\n",
    "        prediction_length=dataset.metadata.prediction_length,\n",
    "        freq=dataset.metadata.freq,\n",
    "        use_feat_static_cat=True,\n",
    "        cardinality=[\n",
    "            feat_static_cat.cardinality\n",
    "            for feat_static_cat in dataset.metadata.feat_static_cat\n",
    "        ],\n",
    "        trainer=Trainer(\n",
    "            epochs=3,\n",
    "            num_batches_per_epoch=10,\n",
    "        ),\n",
    "    )\n",
    "print(f\"Current dataset is {dataset}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 46.29it/s, epoch=1/3, avg_epoch_loss=8.66]\n",
      "100%|██████████| 10/10 [00:00<00:00, 55.59it/s, epoch=2/3, avg_epoch_loss=8.56]\n",
      "100%|██████████| 10/10 [00:00<00:00, 53.14it/s, epoch=3/3, avg_epoch_loss=7.87]\n"
     ]
    }
   ],
   "source": [
    "predictor = estimator.train(dataset.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset.test, predictor=predictor, num_samples=100\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 100%|██████████| 24000/24000 [00:30<00:00, 776.06it/s]\n"
     ]
    }
   ],
   "source": [
    "agg_metrics, item_metrics = Evaluator()(\n",
    "        ts_it, forecast_it, num_series=len(dataset.test)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>MSE</th>\n",
       "      <th>abs_error</th>\n",
       "      <th>abs_target_sum</th>\n",
       "      <th>abs_target_mean</th>\n",
       "      <th>seasonal_error</th>\n",
       "      <th>MASE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>MSIS</th>\n",
       "      <th>...</th>\n",
       "      <th>QuantileLoss[0.5]</th>\n",
       "      <th>Coverage[0.5]</th>\n",
       "      <th>QuantileLoss[0.6]</th>\n",
       "      <th>Coverage[0.6]</th>\n",
       "      <th>QuantileLoss[0.7]</th>\n",
       "      <th>Coverage[0.7]</th>\n",
       "      <th>QuantileLoss[0.8]</th>\n",
       "      <th>Coverage[0.8]</th>\n",
       "      <th>QuantileLoss[0.9]</th>\n",
       "      <th>Coverage[0.9]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>227433.203125</td>\n",
       "      <td>3313.677246</td>\n",
       "      <td>54831.070312</td>\n",
       "      <td>6853.883789</td>\n",
       "      <td>308.422340</td>\n",
       "      <td>1.342995</td>\n",
       "      <td>0.061246</td>\n",
       "      <td>0.058842</td>\n",
       "      <td>13.560884</td>\n",
       "      <td>...</td>\n",
       "      <td>3313.677246</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3655.766406</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3847.881152</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3387.118945</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2303.196484</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>189857.796875</td>\n",
       "      <td>2963.601074</td>\n",
       "      <td>56761.937500</td>\n",
       "      <td>7095.242188</td>\n",
       "      <td>357.911086</td>\n",
       "      <td>1.035034</td>\n",
       "      <td>0.053075</td>\n",
       "      <td>0.051132</td>\n",
       "      <td>11.584008</td>\n",
       "      <td>...</td>\n",
       "      <td>2963.601074</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3334.013281</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3441.122461</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3156.040039</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2206.768457</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>502050.625000</td>\n",
       "      <td>5557.117188</td>\n",
       "      <td>56761.523438</td>\n",
       "      <td>7095.190430</td>\n",
       "      <td>359.439593</td>\n",
       "      <td>1.932563</td>\n",
       "      <td>0.098003</td>\n",
       "      <td>0.093069</td>\n",
       "      <td>13.351615</td>\n",
       "      <td>...</td>\n",
       "      <td>5557.117188</td>\n",
       "      <td>1.000</td>\n",
       "      <td>5617.098047</td>\n",
       "      <td>1.000</td>\n",
       "      <td>5078.002148</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4130.822656</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2936.402930</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>265856.562500</td>\n",
       "      <td>3697.719238</td>\n",
       "      <td>61294.324219</td>\n",
       "      <td>7661.790527</td>\n",
       "      <td>317.977330</td>\n",
       "      <td>1.453610</td>\n",
       "      <td>0.060662</td>\n",
       "      <td>0.058458</td>\n",
       "      <td>16.087560</td>\n",
       "      <td>...</td>\n",
       "      <td>3697.719238</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4140.095312</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4235.002148</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3662.295703</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2638.766211</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>68221.226562</td>\n",
       "      <td>1563.250977</td>\n",
       "      <td>9781.000000</td>\n",
       "      <td>1222.625000</td>\n",
       "      <td>149.800000</td>\n",
       "      <td>1.304448</td>\n",
       "      <td>0.144160</td>\n",
       "      <td>0.154530</td>\n",
       "      <td>10.557169</td>\n",
       "      <td>...</td>\n",
       "      <td>1563.250977</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1629.357764</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1685.173242</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1571.989404</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1333.854639</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>23995.0</td>\n",
       "      <td>29828.621094</td>\n",
       "      <td>1555.552246</td>\n",
       "      <td>17320.000000</td>\n",
       "      <td>2165.000000</td>\n",
       "      <td>23.857143</td>\n",
       "      <td>8.150349</td>\n",
       "      <td>0.089961</td>\n",
       "      <td>0.085934</td>\n",
       "      <td>54.325528</td>\n",
       "      <td>...</td>\n",
       "      <td>1555.552246</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1484.581055</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1410.382031</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1160.693457</td>\n",
       "      <td>1.000</td>\n",
       "      <td>765.431836</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>23996.0</td>\n",
       "      <td>85614.781250</td>\n",
       "      <td>2066.037109</td>\n",
       "      <td>81030.000000</td>\n",
       "      <td>10128.750000</td>\n",
       "      <td>240.571429</td>\n",
       "      <td>1.073505</td>\n",
       "      <td>0.025417</td>\n",
       "      <td>0.024939</td>\n",
       "      <td>25.421861</td>\n",
       "      <td>...</td>\n",
       "      <td>2066.037109</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3292.275000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3913.583789</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3716.085156</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2780.366016</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>23997.0</td>\n",
       "      <td>106081.578125</td>\n",
       "      <td>1688.685547</td>\n",
       "      <td>82040.000000</td>\n",
       "      <td>10255.000000</td>\n",
       "      <td>240.571429</td>\n",
       "      <td>0.877435</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.020295</td>\n",
       "      <td>25.354027</td>\n",
       "      <td>...</td>\n",
       "      <td>1688.685547</td>\n",
       "      <td>0.875</td>\n",
       "      <td>2658.819531</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3653.358398</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3620.185937</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2880.878320</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>23998.0</td>\n",
       "      <td>5154.675781</td>\n",
       "      <td>436.435669</td>\n",
       "      <td>9356.407227</td>\n",
       "      <td>1169.550903</td>\n",
       "      <td>410.208664</td>\n",
       "      <td>0.132992</td>\n",
       "      <td>0.048347</td>\n",
       "      <td>0.046290</td>\n",
       "      <td>1.878267</td>\n",
       "      <td>...</td>\n",
       "      <td>436.435669</td>\n",
       "      <td>0.750</td>\n",
       "      <td>495.234375</td>\n",
       "      <td>1.000</td>\n",
       "      <td>547.170850</td>\n",
       "      <td>1.000</td>\n",
       "      <td>495.582422</td>\n",
       "      <td>1.000</td>\n",
       "      <td>339.674756</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>23999.0</td>\n",
       "      <td>403535.250000</td>\n",
       "      <td>4712.828613</td>\n",
       "      <td>33952.988281</td>\n",
       "      <td>4244.123535</td>\n",
       "      <td>966.669085</td>\n",
       "      <td>0.609416</td>\n",
       "      <td>0.140085</td>\n",
       "      <td>0.129972</td>\n",
       "      <td>3.124030</td>\n",
       "      <td>...</td>\n",
       "      <td>4712.828613</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4537.913672</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4127.616504</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3211.273047</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2066.259277</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id            MSE    abs_error  abs_target_sum  abs_target_mean  \\\n",
       "0          0.0  227433.203125  3313.677246    54831.070312      6853.883789   \n",
       "1          1.0  189857.796875  2963.601074    56761.937500      7095.242188   \n",
       "2          2.0  502050.625000  5557.117188    56761.523438      7095.190430   \n",
       "3          3.0  265856.562500  3697.719238    61294.324219      7661.790527   \n",
       "4          4.0   68221.226562  1563.250977     9781.000000      1222.625000   \n",
       "...        ...            ...          ...             ...              ...   \n",
       "23995  23995.0   29828.621094  1555.552246    17320.000000      2165.000000   \n",
       "23996  23996.0   85614.781250  2066.037109    81030.000000     10128.750000   \n",
       "23997  23997.0  106081.578125  1688.685547    82040.000000     10255.000000   \n",
       "23998  23998.0    5154.675781   436.435669     9356.407227      1169.550903   \n",
       "23999  23999.0  403535.250000  4712.828613    33952.988281      4244.123535   \n",
       "\n",
       "       seasonal_error      MASE      MAPE     sMAPE       MSIS  ...  \\\n",
       "0          308.422340  1.342995  0.061246  0.058842  13.560884  ...   \n",
       "1          357.911086  1.035034  0.053075  0.051132  11.584008  ...   \n",
       "2          359.439593  1.932563  0.098003  0.093069  13.351615  ...   \n",
       "3          317.977330  1.453610  0.060662  0.058458  16.087560  ...   \n",
       "4          149.800000  1.304448  0.144160  0.154530  10.557169  ...   \n",
       "...               ...       ...       ...       ...        ...  ...   \n",
       "23995       23.857143  8.150349  0.089961  0.085934  54.325528  ...   \n",
       "23996      240.571429  1.073505  0.025417  0.024939  25.421861  ...   \n",
       "23997      240.571429  0.877435  0.020563  0.020295  25.354027  ...   \n",
       "23998      410.208664  0.132992  0.048347  0.046290   1.878267  ...   \n",
       "23999      966.669085  0.609416  0.140085  0.129972   3.124030  ...   \n",
       "\n",
       "       QuantileLoss[0.5]  Coverage[0.5]  QuantileLoss[0.6]  Coverage[0.6]  \\\n",
       "0            3313.677246          1.000        3655.766406          1.000   \n",
       "1            2963.601074          1.000        3334.013281          1.000   \n",
       "2            5557.117188          1.000        5617.098047          1.000   \n",
       "3            3697.719238          1.000        4140.095312          1.000   \n",
       "4            1563.250977          0.500        1629.357764          0.625   \n",
       "...                  ...            ...                ...            ...   \n",
       "23995        1555.552246          1.000        1484.581055          1.000   \n",
       "23996        2066.037109          1.000        3292.275000          1.000   \n",
       "23997        1688.685547          0.875        2658.819531          1.000   \n",
       "23998         436.435669          0.750         495.234375          1.000   \n",
       "23999        4712.828613          1.000        4537.913672          1.000   \n",
       "\n",
       "       QuantileLoss[0.7]  Coverage[0.7]  QuantileLoss[0.8]  Coverage[0.8]  \\\n",
       "0            3847.881152          1.000        3387.118945          1.000   \n",
       "1            3441.122461          1.000        3156.040039          1.000   \n",
       "2            5078.002148          1.000        4130.822656          1.000   \n",
       "3            4235.002148          1.000        3662.295703          1.000   \n",
       "4            1685.173242          0.625        1571.989404          0.625   \n",
       "...                  ...            ...                ...            ...   \n",
       "23995        1410.382031          1.000        1160.693457          1.000   \n",
       "23996        3913.583789          1.000        3716.085156          1.000   \n",
       "23997        3653.358398          1.000        3620.185937          1.000   \n",
       "23998         547.170850          1.000         495.582422          1.000   \n",
       "23999        4127.616504          1.000        3211.273047          1.000   \n",
       "\n",
       "       QuantileLoss[0.9]  Coverage[0.9]  \n",
       "0            2303.196484           1.00  \n",
       "1            2206.768457           1.00  \n",
       "2            2936.402930           1.00  \n",
       "3            2638.766211           1.00  \n",
       "4            1333.854639           0.75  \n",
       "...                  ...            ...  \n",
       "23995         765.431836           1.00  \n",
       "23996        2780.366016           1.00  \n",
       "23997        2880.878320           1.00  \n",
       "23998         339.674756           1.00  \n",
       "23999        2066.259277           1.00  \n",
       "\n",
       "[24000 rows x 28 columns]"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 2575691.6912184916,\n",
       " 'abs_error': 146623365.78692627,\n",
       " 'abs_target_sum': 1147074070.9031982,\n",
       " 'abs_target_mean': 5974.344119287491,\n",
       " 'seasonal_error': 473.4332698179725,\n",
       " 'MASE': 1.7481263018363098,\n",
       " 'MAPE': 0.16215688510539863,\n",
       " 'sMAPE': 0.13327629880156988,\n",
       " 'MSIS': 19.247667374065244,\n",
       " 'QuantileLoss[0.1]': 86164699.97987062,\n",
       " 'Coverage[0.1]': 0.15038020833333332,\n",
       " 'QuantileLoss[0.2]': 115243276.25249329,\n",
       " 'Coverage[0.2]': 0.24002083333333332,\n",
       " 'QuantileLoss[0.3]': 132258687.25056762,\n",
       " 'Coverage[0.3]': 0.33919791666666665,\n",
       " 'QuantileLoss[0.4]': 142300527.76174316,\n",
       " 'Coverage[0.4]': 0.44561979166666665,\n",
       " 'QuantileLoss[0.5]': 146623365.69945526,\n",
       " 'Coverage[0.5]': 0.5480260416666667,\n",
       " 'QuantileLoss[0.6]': 144718106.61466676,\n",
       " 'Coverage[0.6]': 0.6331354166666666,\n",
       " 'QuantileLoss[0.7]': 136710986.20660248,\n",
       " 'Coverage[0.7]': 0.7160104166666666,\n",
       " 'QuantileLoss[0.8]': 120371745.21779785,\n",
       " 'Coverage[0.8]': 0.7928385416666667,\n",
       " 'QuantileLoss[0.9]': 91399760.83436279,\n",
       " 'Coverage[0.9]': 0.8674166666666666,\n",
       " 'RMSE': 1604.8961621296537,\n",
       " 'NRMSE': 0.2686313560259157,\n",
       " 'ND': 0.12782379926997742,\n",
       " 'wQuantileLoss[0.1]': 0.07511694507402222,\n",
       " 'wQuantileLoss[0.2]': 0.10046716177774948,\n",
       " 'wQuantileLoss[0.3]': 0.11530091264849883,\n",
       " 'wQuantileLoss[0.4]': 0.12405522134215509,\n",
       " 'wQuantileLoss[0.5]': 0.12782379919372167,\n",
       " 'wQuantileLoss[0.6]': 0.126162826172783,\n",
       " 'wQuantileLoss[0.7]': 0.11918235245170976,\n",
       " 'wQuantileLoss[0.8]': 0.1049380752918754,\n",
       " 'wQuantileLoss[0.9]': 0.07968078361530329,\n",
       " 'mean_absolute_QuantileLoss': 123976795.09083997,\n",
       " 'mean_wQuantileLoss': 0.10808089750753541,\n",
       " 'MAE_Coverage': 0.03468171296296297,\n",
       " 'OWA': nan}"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/home/ttran/Downloads/Yearly-train.txt\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"/home/ttran/Downloads/Yearly-test.txt\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import sktime\n",
    "from sktime.datasets import load_from_tsfile_to_dataframe, load_from_tsfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = os.path.join(os.path.dirname(sktime.__file__), \"datasets/data\")\n",
    "\n",
    "train_x, train_y = load_from_tsfile_to_dataframe(\n",
    "    os.path.join(DATA_PATH, \"ItalyPowerDemand/ItalyPowerDemand_TRAIN.ts\")\n",
    ")\n",
    "test_x, test_y = load_from_tsfile_to_dataframe(\n",
    "    os.path.join(DATA_PATH, \"ItalyPowerDemand/ItalyPowerDemand_TEST.ts\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_x.iloc[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_x[\"dim_0\"].to_numpy()[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_np = train_x.to_numpy()\n",
    "train_x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_np[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[2,3,4], [3,4,5]], columns=[\"dim_0\", \"dim_1\", \"dim_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_np = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_x = train_x.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.common import ListDataset\n",
    "\n",
    "def load_from_tsfile_to_listdataset(\n",
    "    full_file_path_and_name,\n",
    "    return_separate_X_and_y=True,\n",
    "    replace_missing_vals_with=\"NaN\",\n",
    "):\n",
    "    \"\"\"Load data from a .ts file into a Pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    full_file_path_and_name: str\n",
    "        The full pathname of the .ts file to read.\n",
    "    return_separate_X_and_y: bool\n",
    "        true if X and Y values should be returned as separate Data Frames (\n",
    "        X) and a numpy array (y), false otherwise.\n",
    "        This is only relevant for data that\n",
    "    replace_missing_vals_with: str\n",
    "       The value that missing values in the text file should be replaced\n",
    "       with prior to parsing.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame (default) or ndarray (i\n",
    "        If return_separate_X_and_y then a tuple containing a DataFrame and a\n",
    "        numpy array containing the relevant time-series and corresponding\n",
    "        class values.\n",
    "    DataFrame\n",
    "        If not return_separate_X_and_y then a single DataFrame containing\n",
    "        all time-series and (if relevant) a column \"class_vals\" the\n",
    "        associated class values.\n",
    "    \"\"\"\n",
    "    # Initialize flags and variables used when parsing the file\n",
    "    metadata_started = False\n",
    "    data_started = False\n",
    "\n",
    "    has_problem_name_tag = False\n",
    "    has_timestamps_tag = False\n",
    "    has_univariate_tag = False\n",
    "    has_class_labels_tag = False\n",
    "    has_data_tag = False\n",
    "\n",
    "    previous_timestamp_was_int = None\n",
    "    prev_timestamp_was_timestamp = None\n",
    "    num_dimensions = None\n",
    "    is_first_case = True\n",
    "    instance_list = []\n",
    "    class_val_list = []\n",
    "    line_num = 0\n",
    "    # Parse the file\n",
    "    with open(full_file_path_and_name, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            # Strip white space from start/end of line and change to\n",
    "            # lowercase for use below\n",
    "            line = line.strip().lower()\n",
    "            # Empty lines are valid at any point in a file\n",
    "            if line:\n",
    "                # Check if this line contains metadata\n",
    "                # Please note that even though metadata is stored in this\n",
    "                # function it is not currently published externally\n",
    "                if line.startswith(\"@problemname\"):\n",
    "                    # Check that the data has not started\n",
    "                    if data_started:\n",
    "                        raise IOError(\"metadata must come before data\")\n",
    "                    # Check that the associated value is valid\n",
    "                    tokens = line.split(\" \")\n",
    "                    token_len = len(tokens)\n",
    "                    if token_len == 1:\n",
    "                        raise IOError(\"problemname tag requires an associated value\")\n",
    "                    # problem_name = line[len(\"@problemname\") + 1:]\n",
    "                    has_problem_name_tag = True\n",
    "                    metadata_started = True\n",
    "                elif line.startswith(\"@timestamps\"):\n",
    "                    # Check that the data has not started\n",
    "                    if data_started:\n",
    "                        raise IOError(\"metadata must come before data\")\n",
    "                    # Check that the associated value is valid\n",
    "                    tokens = line.split(\" \")\n",
    "                    token_len = len(tokens)\n",
    "                    if token_len != 2:\n",
    "                        raise IOError(\n",
    "                            \"timestamps tag requires an associated Boolean \" \"value\"\n",
    "                        )\n",
    "                    elif tokens[1] == \"true\":\n",
    "                        timestamps = True\n",
    "                    elif tokens[1] == \"false\":\n",
    "                        timestamps = False\n",
    "                    else:\n",
    "                        raise IOError(\"invalid timestamps value\")\n",
    "                    has_timestamps_tag = True\n",
    "                    metadata_started = True\n",
    "                elif line.startswith(\"@univariate\"):\n",
    "                    # Check that the data has not started\n",
    "                    if data_started:\n",
    "                        raise IOError(\"metadata must come before data\")\n",
    "                    # Check that the associated value is valid\n",
    "                    tokens = line.split(\" \")\n",
    "                    token_len = len(tokens)\n",
    "                    if token_len != 2:\n",
    "                        raise IOError(\n",
    "                            \"univariate tag requires an associated Boolean  \" \"value\"\n",
    "                        )\n",
    "                    elif tokens[1] == \"true\":\n",
    "                        # univariate = True\n",
    "                        pass\n",
    "                    elif tokens[1] == \"false\":\n",
    "                        # univariate = False\n",
    "                        pass\n",
    "                    else:\n",
    "                        raise IOError(\"invalid univariate value\")\n",
    "                    has_univariate_tag = True\n",
    "                    metadata_started = True\n",
    "                elif line.startswith(\"@classlabel\"):\n",
    "                    # Check that the data has not started\n",
    "                    if data_started:\n",
    "                        raise IOError(\"metadata must come before data\")\n",
    "                    # Check that the associated value is valid\n",
    "                    tokens = line.split(\" \")\n",
    "                    token_len = len(tokens)\n",
    "                    if token_len == 1:\n",
    "                        raise IOError(\n",
    "                            \"classlabel tag requires an associated Boolean  \" \"value\"\n",
    "                        )\n",
    "                    if tokens[1] == \"true\":\n",
    "                        class_labels = True\n",
    "                    elif tokens[1] == \"false\":\n",
    "                        class_labels = False\n",
    "                    else:\n",
    "                        raise IOError(\"invalid classLabel value\")\n",
    "                    # Check if we have any associated class values\n",
    "                    if token_len == 2 and class_labels:\n",
    "                        raise IOError(\n",
    "                            \"if the classlabel tag is true then class values \"\n",
    "                            \"must be supplied\"\n",
    "                        )\n",
    "                    has_class_labels_tag = True\n",
    "                    class_label_list = [token.strip() for token in tokens[2:]]\n",
    "                    metadata_started = True\n",
    "                # Check if this line contains the start of data\n",
    "                elif line.startswith(\"@data\"):\n",
    "                    if line != \"@data\":\n",
    "                        raise IOError(\"data tag should not have an associated value\")\n",
    "                    if data_started and not metadata_started:\n",
    "                        raise IOError(\"metadata must come before data\")\n",
    "                    else:\n",
    "                        has_data_tag = True\n",
    "                        data_started = True\n",
    "                # If the 'data tag has been found then metadata has been\n",
    "                # parsed and data can be loaded\n",
    "                elif data_started:\n",
    "                    # Check that a full set of metadata has been provided\n",
    "                    if (\n",
    "                        not has_problem_name_tag\n",
    "                        or not has_timestamps_tag\n",
    "                        or not has_univariate_tag\n",
    "                        or not has_class_labels_tag\n",
    "                        or not has_data_tag\n",
    "                    ):\n",
    "                        raise IOError(\n",
    "                            \"a full set of metadata has not been provided \"\n",
    "                            \"before the data\"\n",
    "                        )\n",
    "                    # Replace any missing values with the value specified\n",
    "                    line = line.replace(\"?\", replace_missing_vals_with)\n",
    "                    # Check if we dealing with data that has timestamps\n",
    "                    if timestamps:\n",
    "                        # We're dealing with timestamps so cannot just split\n",
    "                        # line on ':' as timestamps may contain one\n",
    "                        has_another_value = False\n",
    "                        has_another_dimension = False\n",
    "                        timestamp_for_dim = []\n",
    "                        values_for_dimension = []\n",
    "                        this_line_num_dim = 0\n",
    "                        line_len = len(line)\n",
    "                        char_num = 0\n",
    "                        while char_num < line_len:\n",
    "                            # Move through any spaces\n",
    "                            while char_num < line_len and str.isspace(line[char_num]):\n",
    "                                char_num += 1\n",
    "                            # See if there is any more data to read in or if\n",
    "                            # we should validate that read thus far\n",
    "                            if char_num < line_len:\n",
    "                                # See if we have an empty dimension (i.e. no\n",
    "                                # values)\n",
    "                                if line[char_num] == \":\":\n",
    "                                    if len(instance_list) < (this_line_num_dim + 1):\n",
    "                                        instance_list.append([])\n",
    "                                    instance_list[this_line_num_dim].append(\n",
    "                                        pd.Series(dtype=\"object\")\n",
    "                                    )\n",
    "                                    this_line_num_dim += 1\n",
    "                                    has_another_value = False\n",
    "                                    has_another_dimension = True\n",
    "                                    timestamp_for_dim = []\n",
    "                                    values_for_dimension = []\n",
    "                                    char_num += 1\n",
    "                                else:\n",
    "                                    # Check if we have reached a class label\n",
    "                                    if line[char_num] != \"(\" and class_labels:\n",
    "                                        class_val = line[char_num:].strip()\n",
    "                                        if class_val not in class_label_list:\n",
    "                                            raise IOError(\n",
    "                                                \"the class value '\"\n",
    "                                                + class_val\n",
    "                                                + \"' on line \"\n",
    "                                                + str(line_num + 1)\n",
    "                                                + \" is not \"\n",
    "                                                \"valid\"\n",
    "                                            )\n",
    "                                        class_val_list.append(class_val)\n",
    "                                        char_num = line_len\n",
    "                                        has_another_value = False\n",
    "                                        has_another_dimension = False\n",
    "                                        timestamp_for_dim = []\n",
    "                                        values_for_dimension = []\n",
    "                                    else:\n",
    "                                        # Read in the data contained within\n",
    "                                        # the next tuple\n",
    "                                        if line[char_num] != \"(\" and not class_labels:\n",
    "                                            raise IOError(\n",
    "                                                \"dimension \"\n",
    "                                                + str(this_line_num_dim + 1)\n",
    "                                                + \" on line \"\n",
    "                                                + str(line_num + 1)\n",
    "                                                + \" does \"\n",
    "                                                \"not \"\n",
    "                                                \"start \"\n",
    "                                                \"with a \"\n",
    "                                                \"'('\"\n",
    "                                            )\n",
    "                                        char_num += 1\n",
    "                                        tuple_data = \"\"\n",
    "                                        while (\n",
    "                                            char_num < line_len\n",
    "                                            and line[char_num] != \")\"\n",
    "                                        ):\n",
    "                                            tuple_data += line[char_num]\n",
    "                                            char_num += 1\n",
    "                                        if (\n",
    "                                            char_num >= line_len\n",
    "                                            or line[char_num] != \")\"\n",
    "                                        ):\n",
    "                                            raise IOError(\n",
    "                                                \"dimension \"\n",
    "                                                + str(this_line_num_dim + 1)\n",
    "                                                + \" on line \"\n",
    "                                                + str(line_num + 1)\n",
    "                                                + \" does \"\n",
    "                                                \"not end\"\n",
    "                                                \" with a \"\n",
    "                                                \"')'\"\n",
    "                                            )\n",
    "                                        # Read in any spaces immediately\n",
    "                                        # after the current tuple\n",
    "                                        char_num += 1\n",
    "                                        while char_num < line_len and str.isspace(\n",
    "                                            line[char_num]\n",
    "                                        ):\n",
    "                                            char_num += 1\n",
    "\n",
    "                                        # Check if there is another value or\n",
    "                                        # dimension to process after this tuple\n",
    "                                        if char_num >= line_len:\n",
    "                                            has_another_value = False\n",
    "                                            has_another_dimension = False\n",
    "                                        elif line[char_num] == \",\":\n",
    "                                            has_another_value = True\n",
    "                                            has_another_dimension = False\n",
    "                                        elif line[char_num] == \":\":\n",
    "                                            has_another_value = False\n",
    "                                            has_another_dimension = True\n",
    "                                        char_num += 1\n",
    "                                        # Get the numeric value for the\n",
    "                                        # tuple by reading from the end of\n",
    "                                        # the tuple data backwards to the\n",
    "                                        # last comma\n",
    "                                        last_comma_index = tuple_data.rfind(\",\")\n",
    "                                        if last_comma_index == -1:\n",
    "                                            raise IOError(\n",
    "                                                \"dimension \"\n",
    "                                                + str(this_line_num_dim + 1)\n",
    "                                                + \" on line \"\n",
    "                                                + str(line_num + 1)\n",
    "                                                + \" contains a tuple that has \"\n",
    "                                                \"no comma inside of it\"\n",
    "                                            )\n",
    "                                        try:\n",
    "                                            value = tuple_data[last_comma_index + 1 :]\n",
    "                                            value = float(value)\n",
    "                                        except ValueError:\n",
    "                                            raise IOError(\n",
    "                                                \"dimension \"\n",
    "                                                + str(this_line_num_dim + 1)\n",
    "                                                + \" on line \"\n",
    "                                                + str(line_num + 1)\n",
    "                                                + \" contains a tuple that does \"\n",
    "                                                \"not have a valid numeric \"\n",
    "                                                \"value\"\n",
    "                                            )\n",
    "                                        # Check the type of timestamp that\n",
    "                                        # we have\n",
    "                                        timestamp = tuple_data[0:last_comma_index]\n",
    "                                        try:\n",
    "                                            timestamp = int(timestamp)\n",
    "                                            timestamp_is_int = True\n",
    "                                            timestamp_is_timestamp = False\n",
    "                                        except ValueError:\n",
    "                                            timestamp_is_int = False\n",
    "                                        if not timestamp_is_int:\n",
    "                                            try:\n",
    "                                                timestamp = timestamp.strip()\n",
    "                                                timestamp_is_timestamp = True\n",
    "                                            except ValueError:\n",
    "                                                timestamp_is_timestamp = False\n",
    "                                        # Make sure that the timestamps in\n",
    "                                        # the file (not just this dimension\n",
    "                                        # or case) are consistent\n",
    "                                        if (\n",
    "                                            not timestamp_is_timestamp\n",
    "                                            and not timestamp_is_int\n",
    "                                        ):\n",
    "                                            raise IOError(\n",
    "                                                \"dimension \"\n",
    "                                                + str(this_line_num_dim + 1)\n",
    "                                                + \" on line \"\n",
    "                                                + str(line_num + 1)\n",
    "                                                + \" contains a tuple that \"\n",
    "                                                \"has an invalid timestamp '\"\n",
    "                                                + timestamp\n",
    "                                                + \"'\"\n",
    "                                            )\n",
    "                                        if (\n",
    "                                            previous_timestamp_was_int is not None\n",
    "                                            and previous_timestamp_was_int\n",
    "                                            and not timestamp_is_int\n",
    "                                        ):\n",
    "                                            raise IOError(\n",
    "                                                \"dimension \"\n",
    "                                                + str(this_line_num_dim + 1)\n",
    "                                                + \" on line \"\n",
    "                                                + str(line_num + 1)\n",
    "                                                + \" contains tuples where the \"\n",
    "                                                \"timestamp format is \"\n",
    "                                                \"inconsistent\"\n",
    "                                            )\n",
    "                                        if (\n",
    "                                            prev_timestamp_was_timestamp is not None\n",
    "                                            and prev_timestamp_was_timestamp\n",
    "                                            and not timestamp_is_timestamp\n",
    "                                        ):\n",
    "                                            raise IOError(\n",
    "                                                \"dimension \"\n",
    "                                                + str(this_line_num_dim + 1)\n",
    "                                                + \" on line \"\n",
    "                                                + str(line_num + 1)\n",
    "                                                + \" contains tuples where the \"\n",
    "                                                \"timestamp format is \"\n",
    "                                                \"inconsistent\"\n",
    "                                            )\n",
    "                                        # Store the values\n",
    "                                        timestamp_for_dim += [timestamp]\n",
    "                                        values_for_dimension += [value]\n",
    "                                        #  If this was our first tuple then\n",
    "                                        #  we store the type of timestamp we\n",
    "                                        #  had\n",
    "                                        if (\n",
    "                                            prev_timestamp_was_timestamp is None\n",
    "                                            and timestamp_is_timestamp\n",
    "                                        ):\n",
    "                                            prev_timestamp_was_timestamp = True\n",
    "                                            previous_timestamp_was_int = False\n",
    "\n",
    "                                        if (\n",
    "                                            previous_timestamp_was_int is None\n",
    "                                            and timestamp_is_int\n",
    "                                        ):\n",
    "                                            prev_timestamp_was_timestamp = False\n",
    "                                            previous_timestamp_was_int = True\n",
    "                                        # See if we should add the data for\n",
    "                                        # this dimension\n",
    "                                        if not has_another_value:\n",
    "                                            if len(instance_list) < (\n",
    "                                                this_line_num_dim + 1\n",
    "                                            ):\n",
    "                                                instance_list.append([])\n",
    "\n",
    "                                            if timestamp_is_timestamp:\n",
    "                                                timestamp_for_dim = pd.DatetimeIndex(\n",
    "                                                    timestamp_for_dim\n",
    "                                                )\n",
    "\n",
    "                                            instance_list[this_line_num_dim].append(\n",
    "                                                pd.Series(\n",
    "                                                    index=timestamp_for_dim,\n",
    "                                                    data=values_for_dimension,\n",
    "                                                )\n",
    "                                            )\n",
    "                                            this_line_num_dim += 1\n",
    "                                            timestamp_for_dim = []\n",
    "                                            values_for_dimension = []\n",
    "                            elif has_another_value:\n",
    "                                raise IOError(\n",
    "                                    \"dimension \" + str(this_line_num_dim + 1) + \" on \"\n",
    "                                    \"line \"\n",
    "                                    + str(line_num + 1)\n",
    "                                    + \" ends with a ',' that \"\n",
    "                                    \"is not followed by \"\n",
    "                                    \"another tuple\"\n",
    "                                )\n",
    "                            elif has_another_dimension and class_labels:\n",
    "                                raise IOError(\n",
    "                                    \"dimension \" + str(this_line_num_dim + 1) + \" on \"\n",
    "                                    \"line \"\n",
    "                                    + str(line_num + 1)\n",
    "                                    + \" ends with a ':' while \"\n",
    "                                    \"it should list a class \"\n",
    "                                    \"value\"\n",
    "                                )\n",
    "                            elif has_another_dimension and not class_labels:\n",
    "                                if len(instance_list) < (this_line_num_dim + 1):\n",
    "                                    instance_list.append([])\n",
    "                                instance_list[this_line_num_dim].append(\n",
    "                                    pd.Series(dtype=np.float32)\n",
    "                                )\n",
    "                                this_line_num_dim += 1\n",
    "                                num_dimensions = this_line_num_dim\n",
    "                            # If this is the 1st line of data we have seen\n",
    "                            # then note the dimensions\n",
    "                            if not has_another_value and not has_another_dimension:\n",
    "                                if num_dimensions is None:\n",
    "                                    num_dimensions = this_line_num_dim\n",
    "                                if num_dimensions != this_line_num_dim:\n",
    "                                    raise IOError(\n",
    "                                        \"line \"\n",
    "                                        + str(line_num + 1)\n",
    "                                        + \" does not have the \"\n",
    "                                        \"same number of \"\n",
    "                                        \"dimensions as the \"\n",
    "                                        \"previous line of \"\n",
    "                                        \"data\"\n",
    "                                    )\n",
    "                        # Check that we are not expecting some more data,\n",
    "                        # and if not, store that processed above\n",
    "                        if has_another_value:\n",
    "                            raise IOError(\n",
    "                                \"dimension \"\n",
    "                                + str(this_line_num_dim + 1)\n",
    "                                + \" on line \"\n",
    "                                + str(line_num + 1)\n",
    "                                + \" ends with a ',' that is \"\n",
    "                                \"not followed by another \"\n",
    "                                \"tuple\"\n",
    "                            )\n",
    "                        elif has_another_dimension and class_labels:\n",
    "                            raise IOError(\n",
    "                                \"dimension \"\n",
    "                                + str(this_line_num_dim + 1)\n",
    "                                + \" on line \"\n",
    "                                + str(line_num + 1)\n",
    "                                + \" ends with a ':' while it \"\n",
    "                                \"should list a class value\"\n",
    "                            )\n",
    "                        elif has_another_dimension and not class_labels:\n",
    "                            if len(instance_list) < (this_line_num_dim + 1):\n",
    "                                instance_list.append([])\n",
    "                            instance_list[this_line_num_dim].append(\n",
    "                                pd.Series(dtype=\"object\")\n",
    "                            )\n",
    "                            this_line_num_dim += 1\n",
    "                            num_dimensions = this_line_num_dim\n",
    "                        # If this is the 1st line of data we have seen then\n",
    "                        # note the dimensions\n",
    "                        if (\n",
    "                            not has_another_value\n",
    "                            and num_dimensions != this_line_num_dim\n",
    "                        ):\n",
    "                            raise IOError(\n",
    "                                \"line \" + str(line_num + 1) + \" does not have the same \"\n",
    "                                \"number of dimensions as the \"\n",
    "                                \"previous line of data\"\n",
    "                            )\n",
    "                        # Check if we should have class values, and if so\n",
    "                        # that they are contained in those listed in the\n",
    "                        # metadata\n",
    "                        if class_labels and len(class_val_list) == 0:\n",
    "                            raise IOError(\"the cases have no associated class values\")\n",
    "                    else:\n",
    "                        dimensions = line.split(\":\")\n",
    "                        # If first row then note the number of dimensions (\n",
    "                        # that must be the same for all cases)\n",
    "                        if is_first_case:\n",
    "                            num_dimensions = len(dimensions)\n",
    "                            if class_labels:\n",
    "                                num_dimensions -= 1\n",
    "                            for _dim in range(0, num_dimensions):\n",
    "                                instance_list.append([])\n",
    "                            is_first_case = False\n",
    "                        # See how many dimensions that the case whose data\n",
    "                        # in represented in this line has\n",
    "                        this_line_num_dim = len(dimensions)\n",
    "                        if class_labels:\n",
    "                            this_line_num_dim -= 1\n",
    "                        # All dimensions should be included for all series,\n",
    "                        # even if they are empty\n",
    "                        if this_line_num_dim != num_dimensions:\n",
    "                            raise IOError(\n",
    "                                \"inconsistent number of dimensions. \"\n",
    "                                \"Expecting \"\n",
    "                                + str(num_dimensions)\n",
    "                                + \" but have read \"\n",
    "                                + str(this_line_num_dim)\n",
    "                            )\n",
    "                        # Process the data for each dimension\n",
    "                        for dim in range(0, num_dimensions):\n",
    "                            dimension = dimensions[dim].strip()\n",
    "\n",
    "                            if dimension:\n",
    "                                data_series = dimension.split(\",\")\n",
    "                                data_series = [float(i) for i in data_series]\n",
    "                                instance_list[dim].append(pd.Series(data_series))\n",
    "                            else:\n",
    "                                instance_list[dim].append(pd.Series(dtype=\"object\"))\n",
    "                        if class_labels:\n",
    "                            class_val_list.append(dimensions[num_dimensions].strip())\n",
    "            line_num += 1\n",
    "    # Check that the file was not empty\n",
    "    if line_num:\n",
    "        # Check that the file contained both metadata and data\n",
    "        if metadata_started and not (\n",
    "            has_problem_name_tag\n",
    "            and has_timestamps_tag\n",
    "            and has_univariate_tag\n",
    "            and has_class_labels_tag\n",
    "            and has_data_tag\n",
    "        ):\n",
    "            raise IOError(\"metadata incomplete\")\n",
    "\n",
    "        elif metadata_started and not data_started:\n",
    "            raise IOError(\"file contained metadata but no data\")\n",
    "\n",
    "        elif metadata_started and data_started and len(instance_list) == 0:\n",
    "            raise IOError(\"file contained metadata but no data\")\n",
    "        # Create a ListDataset from the data parsed above\n",
    "        \n",
    "        data = pd.DataFrame(dtype=np.float32)\n",
    "        for dim in range(0, num_dimensions):\n",
    "            data[\"dim_\" + str(dim)] = instance_list[dim]\n",
    "\n",
    "        # the original dataset did not include time stamps, so we use the earliest\n",
    "        # point available in pandas as the start date for each time series.\n",
    "        dummy_start = [\n",
    "        pd.Timestamp(\"04-18-2022\", freq='1H')  # Arbitrary default date\n",
    "        for _ in range(len(data))]    \n",
    "\n",
    "        nested_target, feat_static_cat = create_dataset(data, class_val_list)\n",
    "\n",
    "        train_ds = ListDataset(\n",
    "    [\n",
    "        {\n",
    "            \"target\": target,\n",
    "            \"start\": start,\n",
    "            \"fea_static_cat\": [fsc]\n",
    "        }\n",
    "        for (target, start, fsc) in zip(\n",
    "            nested_target,\n",
    "            dummy_start,\n",
    "            feat_static_cat\n",
    "        )\n",
    "    ],\n",
    "    freq='1H'\n",
    ")\n",
    "\n",
    "        # Check if we should return any associated class labels separately\n",
    "        if class_labels:\n",
    "            if return_separate_X_and_y:\n",
    "                return train_ds, np.asarray(class_val_list)\n",
    "        else:\n",
    "            return train_ds\n",
    "    else:\n",
    "        raise IOError(\"empty file\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_dataset(data, label):\n",
    "    list_len = len([num for sublist in pd.Series(data.loc[0]) for num in sublist])\n",
    "    nested_target = np.empty([1,list_len])\n",
    "    \n",
    "    for x in range(len(data)):\n",
    "        flat_list = np.expand_dims(np.array([num for sublist in pd.Series(data.loc[x]) for num in sublist]), axis=0)\n",
    "        nested_target = np.append(nested_target, flat_list, axis=0)\n",
    "        #nested_target.append(flat_list)\n",
    "    nested_target = np.delete(nested_target,0,0)\n",
    "\n",
    "    # create categorical static feats: pass in train_y\n",
    "    feat_static_cat = label\n",
    "\n",
    "    return nested_target, feat_static_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dict(\n",
    "    target_values,\n",
    "    start\n",
    "):\n",
    "\n",
    "    res = {\n",
    "        \"start\": start,\n",
    "        \"target\": target_values,\n",
    "    }\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = load_from_tsfile_to_listdataset(\n",
    "    os.path.join(DATA_PATH, \"ItalyPowerDemand/ItalyPowerDemand_TRAIN.ts\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_entry = next(iter(train_x))\n",
    "ListDataset_check = train_entry[\"target\"]\n",
    "ListDataset_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "b=[[3,4], [5,6], [7,8]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0,:]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c690c4aacf52c5b35e8c405d3ffa01c0fb45d098d01a1254237bffad00a0de1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('sktime-gluon-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
